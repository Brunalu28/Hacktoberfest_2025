{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaLX_FB22cJo"
      },
      "source": [
        "### CÃ‰LULA 0: ImportaÃ§Ã£o de Bibliotecas Essenciais ğŸ› ï¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4lST9KP0F4g",
        "outputId": "54e0b8e9-d337-43f8-db59-04728d229cf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/323.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hpypdf instalado com sucesso!\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU pypdf\n",
        "print(\"pypdf instalado com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPK9ZTmQ0KAv"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp0fNolJfO0e",
        "outputId": "7871395d-73f9-46e3-a4c2-ffa11834d12c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/107.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/467.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m467.1/467.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain # LangChain Ã© Ãºtil para abstrair a interaÃ§Ã£o com o LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M850t4mYgG-z",
        "outputId": "fc9ebb06-8cff-4024-9ee8-d42360fda886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.7/50.7 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "llama-cpp-python instalado com sucesso!\n",
            "DependÃªncias instaladas.\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU llama-cpp-python\n",
        "# Verifica se a instalaÃ§Ã£o do llama-cpp-python foi bem-sucedida\n",
        "try:\n",
        "    from llama_cpp import Llama\n",
        "    print(\"llama-cpp-python instalado com sucesso!\")\n",
        "except ImportError:\n",
        "    print(\"Erro na instalaÃ§Ã£o do llama-cpp-python. Verifique as saÃ­das acima.\")\n",
        "    print(\"Se a instalaÃ§Ã£o com CUDA falhou, tente comentar a primeira linha de instalaÃ§Ã£o e descomentar a segunda.\")\n",
        "\n",
        "print(\"DependÃªncias instaladas.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YP5GRRRhMHi",
        "outputId": "2b006262-e9e7-45db-d7b4-de6979395162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/566.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m563.2/566.1 kB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Instala a biblioteca huggingface_hub para baixar modelos\n",
        "!pip install -qU huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI4wjLbGnyp7",
        "outputId": "e2c74c3f-538d-4110-869d-0ae273e6595a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m147.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-community # NecessÃ¡rio para LlamaCpp e outras integraÃ§Ãµes da LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305,
          "referenced_widgets": [
            "49f1e8adc9e143299dd0cd55c4ce0092",
            "46c9c266c45f44c8bce85308c3bffde6",
            "d38f81a7fb79460f977e70fd6baefe05",
            "024513b70b5a4d4d9ededc3a11af28fd",
            "20f6eb04dccb4b478abaf581829a83e8",
            "0549998d037741a0a654223f7daf46b5",
            "62a7b8267f9c478284ca315350c72692",
            "b1811f8d11c943819b3c949a643d6183",
            "d9066538d1cd4150be9b008734320ad4",
            "2b43164e391b4b2d99b351354f99b785",
            "ed80012eb9994d8591a591133ce617d7"
          ]
        },
        "id": "c0meTqoghUAp",
        "outputId": "9d366e88-58fd-4205-cde9-45477607d59d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baixando o modelo mistral-7b-instruct-v0.2.Q4_K_M.gguf de TheBloke/Mistral-7B-Instruct-v0.2-GGUF...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49f1e8adc9e143299dd0cd55c4ce0092",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "mistral-7b-instruct-v0.2.Q4_K_M.gguf:   0%|          | 0.00/4.37G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download do modelo concluÃ­do!\n",
            "Caminho do modelo: ./models/mistral-7b-instruct-v0.2.Q4_K_M.gguf\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "import os\n",
        "\n",
        "model_name = \"mistral-7b-instruct-v0.2.Q4_K_M.gguf\" # Altere para o nome do novo arquivo GGUF\n",
        "model_repo_id = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\" # Altere para o novo repositÃ³rio\n",
        "# Define o diretÃ³rio onde o modelo serÃ¡ salvo\n",
        "model_dir = \"./models\"\n",
        "os.makedirs(model_dir, exist_ok=True) # Cria o diretÃ³rio se nÃ£o existir\n",
        "\n",
        "# Caminho completo para o modelo\n",
        "model_path = os.path.join(model_dir, model_name)\n",
        "\n",
        "# Verifica se o modelo jÃ¡ existe para evitar download repetido\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Baixando o modelo {model_name} de {model_repo_id}...\")\n",
        "    hf_hub_download(\n",
        "        repo_id=model_repo_id,\n",
        "        filename=model_name,\n",
        "        local_dir=model_dir,\n",
        "        local_dir_use_symlinks=False # Importante para Colab\n",
        "    )\n",
        "    print(\"Download do modelo concluÃ­do!\")\n",
        "else:\n",
        "    print(f\"O modelo {model_name} jÃ¡ existe em {model_dir}. Pulando o download.\")\n",
        "\n",
        "print(f\"Caminho do modelo: {model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuALBJqwhiLu",
        "outputId": "091ab842-6e6a-4e12-d93b-2e923a42baa0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
            "llama_context: n_ctx_per_seq (2048) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Modelo LLM inicializado com sucesso!\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain_core.callbacks.manager import CallbackManager\n",
        "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "# Configura o callback para streaming da saÃ­da\n",
        "#callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=model_path, # Caminho para o modelo GGUF\n",
        "    n_ctx=2048,           # Contexto mÃ¡ximo de tokens (ajuste conforme o modelo)\n",
        "    n_gpu_layers=-1,      # Descarrega todas as camadas para a GPU (se disponÃ­vel)\n",
        "    n_threads=os.cpu_count(), # Usa o nÃºmero de threads da CPU disponÃ­vel\n",
        "    temperature=0.3,      # Reduzido para tornar as respostas mais determinÃ­sticas\n",
        "    max_tokens=100,       # Ajustado para garantir que a resposta completa seja gerada\n",
        "    verbose=False          # SaÃ­da detalhada\n",
        ")\n",
        "#callback_manager=callback_manager, # Para ver a saÃ­da em tempo real\n",
        "print(\"\\nModelo LLM inicializado com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fIpWilgovdu"
      },
      "source": [
        "### CÃ‰LULA 1: ImportaÃ§Ã£o de Bibliotecas Essenciais ğŸ“š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGSeqrwiihbZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2r41ydKo-Qu"
      },
      "source": [
        "### CÃ‰LULA 2: ConfiguraÃ§Ã£o do Webhook do Discord âš™ï¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjvUeyEZiIyk"
      },
      "outputs": [],
      "source": [
        "# Substitua este URL pelo Webhook URL que vocÃª copiou do Discord\n",
        "DISCORD_WEBHOOK_URL_PLACEHOLDER = \"COLE SEU WEBHOOK AQUI\"\n",
        "\n",
        "DISCORD_WEBHOOK_URL = os.getenv(\"DISCORD_WEBHOOK_URL\", DISCORD_WEBHOOK_URL_PLACEHOLDER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Mu1xlh3pKCp"
      },
      "source": [
        "### CÃ‰LULA 3: Cadeia de AnÃ¡lise PDFs (LLMChain) ğŸ§ \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myYWFXjtiMmi"
      },
      "outputs": [],
      "source": [
        "slide_summary_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"VocÃª Ã© um assistente de estudo prestativo.\n",
        "Crie um resumo conciso, com no mÃ¡ximo 20 linhas, do seguinte texto de slide.\n",
        "O resumo deve focar nas ideias centrais, usar linguagem simples e ter um tom informativo e amigÃ¡vel para auxiliar estudantes.\n",
        "\n",
        "Texto do Slide: \"{texto_do_slide}\"\n",
        "\n",
        "Resumo:\"\"\"\n",
        ")\n",
        "# Remove o 'stop' para permitir um resumo mais longo\n",
        "slide_summary_chain = slide_summary_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peAo2IyYpU8q"
      },
      "source": [
        "### CÃ‰LULA 4: Cadeia de SugestÃ£o de Resposta ao Cliente (LLMChain) ğŸ’¬\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFIIK8isiPQQ"
      },
      "outputs": [],
      "source": [
        "key_concepts_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"Analise o seguinte texto de slide e identifique os 3-5 conceitos mais importantes.\n",
        "Liste cada conceito em uma linha separada, comeÃ§ando com um hÃ­fen.\n",
        "\n",
        "Texto do Slide: \"{texto_do_slide}\"\n",
        "\n",
        "Conceitos-Chave:\"\"\"\n",
        ")\n",
        "key_concepts_chain = key_concepts_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xzu9txZ9pcA4"
      },
      "source": [
        "### CÃ‰LULA 5: Cadeia de AvaliaÃ§Ã£o de Prioridade (LLMChain) ğŸš€\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aJMKwAtiR6s"
      },
      "outputs": [],
      "source": [
        "study_questions_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"Com base no seguinte texto de slide, crie 2-3 perguntas de estudo que ajudem os estudantes a testar seu entendimento do conteÃºdo.\n",
        "As perguntas devem ser claras e focadas nos pontos principais.\n",
        "\n",
        "Texto do Slide: \"{texto_do_slide}\"\n",
        "\n",
        "Perguntas de Estudo:\"\"\"\n",
        ")\n",
        "study_questions_chain = study_questions_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS6j1YWOpeoG"
      },
      "source": [
        "### CÃ‰LULA 6: FunÃ§Ã£o para enviar mensagens ao Discord ğŸš€\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Adng5CbviUMO"
      },
      "outputs": [],
      "source": [
        "def send_discord_message(text: str, webhook_url: str, username: str = \"Assistente de Estudos\", avatar_url: str = None):\n",
        "    \"\"\"\n",
        "    Envia uma mensagem de texto para o Discord usando um webhook.\n",
        "    \"\"\"\n",
        "    if not webhook_url or \"discord.com/api/webhooks\" not in webhook_url:\n",
        "        print(f\"ERRO: Discord Webhook URL invÃ¡lido ou nÃ£o configurado. Mensagem nÃ£o enviada: '{text}'\")\n",
        "        return\n",
        "\n",
        "    payload = {\n",
        "        \"content\": text,\n",
        "        \"username\": username,\n",
        "        \"avatar_url\": avatar_url\n",
        "    }\n",
        "    try:\n",
        "        response = requests.post(webhook_url, json=payload)\n",
        "        response.raise_for_status() # LanÃ§a exceÃ§Ã£o para erros HTTP (4xx ou 5xx)\n",
        "        print(f\"\\n[INTEGRAÃ‡ÃƒO DISCORD] Mensagem enviada com sucesso para o Discord!\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\n[ERRO DISCORD] Falha ao enviar mensagem para o Discord: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfmZHH958nI4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_glued_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Tenta corrigir palavras grudadas em um texto, inserindo espaÃ§os.\n",
        "\n",
        "    Argumentos:\n",
        "        text (str): O texto extraÃ­do do PDF.\n",
        "\n",
        "    Retorna:\n",
        "        str: O texto prÃ©-processado.\n",
        "    \"\"\"\n",
        "    # 1. Trata quebras de linha e retornos de carro que podem ter vindo da extraÃ§Ã£o\n",
        "    processed_text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
        "\n",
        "    # 2. Insere espaÃ§o entre letra minÃºscula e letra MAIÃšSCULA\n",
        "    # Ex: 'umEndereÃ§o' -> 'um EndereÃ§o'\n",
        "    processed_text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', processed_text)\n",
        "\n",
        "    # 3. Insere espaÃ§o entre letra e nÃºmero\n",
        "    # Ex: 'pergunta1' -> 'pergunta 1'\n",
        "    processed_text = re.sub(r'([a-zA-Z])([0-9])', r'\\1 \\2', processed_text)\n",
        "\n",
        "    # 4. Insere espaÃ§o entre nÃºmero e letra\n",
        "    # Ex: '1pergunta' -> '1 pergunta'\n",
        "    processed_text = re.sub(r'([0-9])([a-zA-Z])', r'\\1 \\2', processed_text)\n",
        "\n",
        "    # 5. Remove espaÃ§os duplos ou mÃºltiplos criados pelas substituiÃ§Ãµes\n",
        "    processed_text = re.sub(r'\\s+', ' ', processed_text).strip()\n",
        "\n",
        "    return processed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqyQPAXT0U-h"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Carrega um PDF, extrai, concatena e prÃ©-processa o texto de todas as pÃ¡ginas.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Carrega o documento usando PyPDFLoader\n",
        "        loader = PyPDFLoader(pdf_path)\n",
        "        pages = loader.load()\n",
        "\n",
        "        # 2. Concatena o conteÃºdo das pÃ¡ginas (texto bruto)\n",
        "        # Note: A quebra de linha '\\n' aqui Ã© do prÃ³prio texto do PDF.\n",
        "        # O preprocessamento vai tratar isso.\n",
        "        full_text_bruto = \"\\n\".join(page.page_content for page in pages)\n",
        "\n",
        "        # 3. *** PASSO ADICIONAL: PRÃ‰-PROCESSAR O TEXTO ***\n",
        "        full_text_processado = preprocess_glued_text(full_text_bruto)\n",
        "        # *************************************************\n",
        "\n",
        "        print(f\"Sucesso! Texto extraÃ­do e prÃ©-processado de {len(pages)} pÃ¡ginas do PDF.\")\n",
        "\n",
        "        # Retorna o texto LIMPO\n",
        "        return full_text_processado\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERRO: Arquivo PDF nÃ£o encontrado no caminho: {pdf_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"ERRO ao processar o PDF: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCfHOwlPpzS7"
      },
      "source": [
        "### CÃ‰LULA 7: CÃ©lula de Testes com Feedbacks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXJOElN7iW27",
        "outputId": "bcce4db8-c309-415f-aa0d-860f1664cab6"
      },
      "outputs": [],
      "source": [
        "# CÃ©lula de Testes com Materiais de Estudo (AGORA COM PDF)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Extrair e Processar o texto do PDF\n",
        "    pdf_file_name = \"ADICIONE O SEU PDF AQUI\"\n",
        "    # O texto retornado jÃ¡ estÃ¡ PRÃ‰-PROCESSADO!\n",
        "    texto_do_pdf_limpo = extract_text_from_pdf(pdf_file_name)\n",
        "\n",
        "    if texto_do_pdf_limpo:\n",
        "\n",
        "        # O texto de entrada do LLM Ã© o texto limpo\n",
        "        texto_para_llm = texto_do_pdf_limpo[:1500]\n",
        "\n",
        "        print(f\"\\n--- Processando Texto ExtraÃ­do do PDF ({pdf_file_name}) ---\\n\")\n",
        "        print(f\"Texto Original (InÃ­cio):\\n{texto_para_llm[:500]}...\\n\") # Mostra o comeÃ§o\n",
        "\n",
        "        # Passo 1: Resumo do Slide/Texto\n",
        "        resumo_pdf = slide_summary_chain.invoke({\"texto_do_slide\": texto_para_llm}).strip()\n",
        "        print(f\"\\nResumo: {resumo_pdf}\")\n",
        "\n",
        "        # Passo 2: Conceitos-Chave\n",
        "        conceitos_pdf = key_concepts_chain.invoke({\"texto_do_slide\": texto_para_llm}).strip()\n",
        "        print(f\"\\nConceitos-Chave: {conceitos_pdf}\")\n",
        "\n",
        "        # Passo 3: Perguntas de Estudo\n",
        "        perguntas_pdf = study_questions_chain.invoke({\"texto_do_slide\": texto_para_llm}).strip()\n",
        "        print(f\"\\nPerguntas de Estudo: {perguntas_pdf}\")\n",
        "\n",
        "        # Enviar para o Discord\n",
        "        discord_message_pdf = (\n",
        "            f\"**NOVO RESUMO DE ESTUDO (PDF: {pdf_file_name})**\\\\n\"\\\n",
        "            f\"> **Slide Original (Trecho):**\\\\n```\\\\n{texto_para_llm[:300]}...\\\\n```\\\\n\"\\\n",
        "            f\"> **Resumo:**\\\\n```\\\\n{resumo_pdf}\\\\n```\\\\n\"\\\n",
        "            f\"> **Conceitos-Chave:**\\\\n```\\\\n{conceitos_pdf}\\\\n```\\\\n\"\\\n",
        "            f\"> **Perguntas de Estudo:**\\\\n```\\\\n{perguntas_pdf}\\\\n```\"\n",
        "        )\n",
        "        send_discord_message(discord_message_pdf, DISCORD_WEBHOOK_URL, username=f\"Assistente de Estudos - {pdf_file_name}\")\n",
        "\n",
        "    else:\n",
        "        print(\"NÃ£o foi possÃ­vel processar o PDF. Verifique o caminho do arquivo.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "024513b70b5a4d4d9ededc3a11af28fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b43164e391b4b2d99b351354f99b785",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ed80012eb9994d8591a591133ce617d7",
            "value": "â€‡4.37G/4.37Gâ€‡[01:08&lt;00:00,â€‡110MB/s]"
          }
        },
        "0549998d037741a0a654223f7daf46b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20f6eb04dccb4b478abaf581829a83e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b43164e391b4b2d99b351354f99b785": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46c9c266c45f44c8bce85308c3bffde6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0549998d037741a0a654223f7daf46b5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_62a7b8267f9c478284ca315350c72692",
            "value": "mistral-7b-instruct-v0.2.Q4_K_M.gguf:â€‡100%"
          }
        },
        "49f1e8adc9e143299dd0cd55c4ce0092": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46c9c266c45f44c8bce85308c3bffde6",
              "IPY_MODEL_d38f81a7fb79460f977e70fd6baefe05",
              "IPY_MODEL_024513b70b5a4d4d9ededc3a11af28fd"
            ],
            "layout": "IPY_MODEL_20f6eb04dccb4b478abaf581829a83e8"
          }
        },
        "62a7b8267f9c478284ca315350c72692": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1811f8d11c943819b3c949a643d6183": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d38f81a7fb79460f977e70fd6baefe05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1811f8d11c943819b3c949a643d6183",
            "max": 4368439584,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9066538d1cd4150be9b008734320ad4",
            "value": 4368439584
          }
        },
        "d9066538d1cd4150be9b008734320ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed80012eb9994d8591a591133ce617d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
